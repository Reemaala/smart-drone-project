{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8370a-4662-4b8d-9959-d6aab10b17b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0a8370a-4662-4b8d-9959-d6aab10b17b9",
    "outputId": "ee1fb440-446e-4a29-e353-46013fb789c1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z54fY5Y7M8ZC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z54fY5Y7M8ZC",
    "outputId": "a25e8f05-0d46-4336-846a-6cf477419a6c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1sF9DsWNIhP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1sF9DsWNIhP",
    "outputId": "a658469b-da52-46f5-d9b1-ccedf1788c60"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/content/drive/MyDrive/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6J-O50ZrNMH1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J-O50ZrNMH1",
    "outputId": "c56db2eb-711e-4300-ebf0-93e2d4813bcd"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/drive/MyDrive/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "okzfy6_6NO8L",
   "metadata": {
    "id": "okzfy6_6NO8L"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gN79ALWpNU7L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN79ALWpNU7L",
    "outputId": "88616a37-9d04-44c0-c355-7632101f4b42"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_dir = '/content/drive/MyDrive/train'\n",
    "test_dir = '/content/drive/MyDrive/test'\n",
    "\n",
    "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "    raise FileNotFoundError(\"‚ùå Dataset directory not found. Check your file paths.\")\n",
    "\n",
    "def remove_missing_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"üö´ Skipping missing file: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "remove_missing_files(train_dir)\n",
    "remove_missing_files(test_dir)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04PbxskZPysF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04PbxskZPysF",
    "outputId": "f4f23e31-36b9-4608-ddf4-d7d7085fcbd9"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aOnaTopsP9fT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "aOnaTopsP9fT",
    "outputId": "93ad139a-ce43-4261-8b67-df59be8c450d"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eTVdajXUQHEE",
   "metadata": {
    "id": "eTVdajXUQHEE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HwALOqvMQCL1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwALOqvMQCL1",
    "outputId": "df39923c-cdd0-4577-970e-7ee5974b9455"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = '/content/drive/MyDrive/test/fire/fire1.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "print(f\" Predicted Event: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JvyOV3qlQIX6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvyOV3qlQIX6",
    "outputId": "d61e47ba-9568-4ba9-ed4a-cadd24d8af4b"
   },
   "outputs": [],
   "source": [
    "if predicted_class == 'dense_crowd':\n",
    "    print(\"ALERT: Dense crowd detected! Take immediate action.\")\n",
    "elif predicted_class == 'moderate_crowd':\n",
    "    print(\"Notice: Moderate crowd detected.\")\n",
    "elif predicted_class == 'sparse_crowd':\n",
    "    print(\"Sparse crowd detected. All clear.\")\n",
    "elif predicted_class == 'heat_stroke':\n",
    "    print(\"ALERT: Heat stroke signs detected! Send medical assistance.\")\n",
    "elif predicted_class == 'fainting':\n",
    "    print(\"ALERT: Fainting detected! Provide first aid.\")\n",
    "elif predicted_class == 'stampede':\n",
    "    print(\"ALERT: Stampede risk! Take crowd control measures.\")\n",
    "elif predicted_class == 'fire':\n",
    "    print(\"ALERT: Fire detected! Deploy firefighting resources immediately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3wrWbKrQM3X",
   "metadata": {
    "id": "b3wrWbKrQM3X"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/crowd_fire_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ux5smll0QPwT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ux5smll0QPwT",
    "outputId": "95c22f27-615e-4d0f-b5e0-c42bc3bdc1f3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('/content/drive/MyDrive/crowd_fire_model.keras')\n",
    "print(\"‚úÖ Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rRB97mTTRSsZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRB97mTTRSsZ",
    "outputId": "2e8bc9f5-de2e-4813-da98-667f63a6e45f"
   },
   "outputs": [],
   "source": [
    "!ngrok config add-authtoken 2tH860vipU68sBaoNOaniZITgOQ_6cNqevwesNNxVcs2JbnKL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xkSLJOZBRcwB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkSLJOZBRcwB",
    "outputId": "9821e134-acde-4afe-8a27-3f7aec60be9a"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"üåê Public URL:\", public_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mjjp2ko0Q_Cs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjjp2ko0Q_Cs",
    "outputId": "079a2a99-51a6-492f-d0ef-579995c19ce6"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from pyngrok import ngrok\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "model = load_model('/content/drive/MyDrive/crowd_fire_model.keras')\n",
    "\n",
    "\n",
    "class_names = ['dense_crowd', 'fainting', 'fire', 'moderate_crowd', 'sparse_crowd']\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        if 'image' not in request.files:\n",
    "            print(\"‚ùå No image in request\")\n",
    "            return jsonify({\"error\": \"No image uploaded\"}), 400\n",
    "\n",
    "       \n",
    "        f = request.files['image']\n",
    "        temp_path = \"temp.jpg\"\n",
    "        f.save(temp_path)\n",
    "\n",
    "     \n",
    "        img = image.load_img(temp_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "      \n",
    "        predictions = model.predict(img_array)\n",
    "        label = class_names[np.argmax(predictions)]\n",
    "\n",
    "        os.remove(temp_path)\n",
    "        print(\"‚úÖ Prediction:\", label)\n",
    "        return jsonify({\"label\": label})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Internal server error:\", str(e))\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"üåê Public URL:\", public_url)\n",
    "\n",
    "\n",
    "app.run(port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WoO_AGMOQmjH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "WoO_AGMOQmjH",
    "outputId": "be1f849e-718e-4738-97cf-b5b89bc145dd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('/Users/reham/saved_models/model.h5')\n",
    "\n",
    "# Class names (if you don't have train_generator anymore)\n",
    "class_names = ['dense_crowd', 'fainting', 'fire', 'moderate_crowd', 'sparse_crowd']\n",
    "\n",
    "# Path to test images\n",
    "test_images_dir = 'downloads/test/'\n",
    "\n",
    "# Collect image paths\n",
    "image_paths = []\n",
    "for class_name in os.listdir(test_images_dir):\n",
    "    class_folder = os.path.join(test_images_dir, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(class_folder, filename))\n",
    "\n",
    "# Predict each image\n",
    "for img_path in image_paths:\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predicted Event: {predicted_class}\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image: {img_path} | Predicted Event: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3d21e-a0cf-4295-b8d6-e1b6dd03a5d1",
   "metadata": {
    "id": "1df3d21e-a0cf-4295-b8d6-e1b6dd03a5d1"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'downloads/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'downloads/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f7227-e88e-4b29-a6dc-5203247d8c45",
   "metadata": {
    "id": "b08f7227-e88e-4b29-a6dc-5203247d8c45"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')  # 7 classes for dense crowd, moderate crowd, sparse crowd, heat stroke, fainting, stampede, and fire\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483c475-ae55-4d71-9522-dce7e528fff3",
   "metadata": {
    "id": "5483c475-ae55-4d71-9522-dce7e528fff3",
    "outputId": "f10f06f4-af31-4b95-c3dd-d7a0ab216129"
   },
   "outputs": [],
   "source": [
    "# Ensure dataset directories exist\n",
    "if not os.path.exists ('downloads/train') or not os.path.exists('downloads/test'):\n",
    "    raise FileNotFoundError(\"Dataset directory not found. Check your file paths.\")\n",
    "\n",
    "# Remove missing files before training\n",
    "def remove_missing_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if not os.path.exists('downloads/train'):\n",
    "                print(f\"Skipping missing file: {'downloads/train'}\")\n",
    "                os.remove('downloads/train')  # Remove broken file reference\n",
    "\n",
    "remove_missing_files('downloads/train')\n",
    "remove_missing_files ('downloads/test')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80282fd-bea7-4fb0-bcbc-3f50f0bd15f6",
   "metadata": {
    "id": "b80282fd-bea7-4fb0-bcbc-3f50f0bd15f6",
    "outputId": "952e6e8d-8db9-4578-c4dc-c4e2e647de0c"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e0a8b-9ecf-46bb-a51b-2aad041d550a",
   "metadata": {
    "id": "d77e0a8b-9ecf-46bb-a51b-2aad041d550a",
    "outputId": "240051a2-076a-44b8-d54a-7431fe791a8c"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0d9ec-c925-4f8a-b33c-c51e76b776c0",
   "metadata": {
    "id": "99c0d9ec-c925-4f8a-b33c-c51e76b776c0",
    "outputId": "6f7a845f-23cd-434c-e261-7a090210481a"
   },
   "outputs": [],
   "source": [
    "img_path = 'downloads/test/fire/fire1.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "print(f\"Predicted Event: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8714f7a-8acb-458d-b036-03b18a8d8786",
   "metadata": {
    "id": "b8714f7a-8acb-458d-b036-03b18a8d8786",
    "outputId": "c75572c1-850f-4620-962f-638e727aa315"
   },
   "outputs": [],
   "source": [
    "class_weights = {0: 1.0, 1: 2.0, 2: 3.0, 3: 3.0, 4: 4.0, 5: 5.0}\n",
    "model.fit(train_generator, epochs=10, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af9b71-402a-47fd-80b6-3db938c272e5",
   "metadata": {
    "id": "58af9b71-402a-47fd-80b6-3db938c272e5",
    "outputId": "849c971c-afb3-47f7-d25d-29b041f91f2f"
   },
   "outputs": [],
   "source": [
    "img_path = 'downloads/test/fire/fire1.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "print(f\"Predicted Event: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95214ca-474b-41e0-82ca-60b309ccdf82",
   "metadata": {
    "id": "e95214ca-474b-41e0-82ca-60b309ccdf82",
    "outputId": "4e84c569-58b5-41c1-a9c5-ce2cc98f4457"
   },
   "outputs": [],
   "source": [
    "if predicted_class == 'dense_crowd':\n",
    "    print(\"ALERT: Dense crowd detected! Take immediate action.\")\n",
    "elif predicted_class == 'moderate_crowd':\n",
    "    print(\"Notice: Moderate crowd detected.\")\n",
    "elif predicted_class == 'sparse_crowd':\n",
    "    print(\"Sparse crowd detected. All clear.\")\n",
    "elif predicted_class == 'heat_stroke':\n",
    "    print(\"ALERT: Heat stroke signs detected! Send medical assistance.\")\n",
    "elif predicted_class == 'fainting':\n",
    "    print(\"ALERT: Fainting detected! Provide first aid.\")\n",
    "elif predicted_class == 'stampede':\n",
    "    print(\"ALERT: Stampede risk! Take crowd control measures.\")\n",
    "elif predicted_class == 'fire':\n",
    "    print(\"ALERT: Fire detected! Deploy firefighting resources immediately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ec29d-ecf2-434d-8251-6d7458266088",
   "metadata": {
    "id": "c15ec29d-ecf2-434d-8251-6d7458266088",
    "outputId": "539a941c-cc7d-4771-af91-08fb766841c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('/Users/reham/saved_models/model.h5')\n",
    "\n",
    "# Load your trained model (replace with your actual model path)\n",
    "model = load_model('/Users/reham/saved_models/model.h5')\n",
    "\n",
    "# Directory containing the test images (adjust path as needed)\n",
    "test_images_dir = 'downloads/test/'\n",
    "\n",
    "# Get all image file paths in the test_images_dir\n",
    "image_paths = []\n",
    "for class_name in os.listdir(test_images_dir):\n",
    "    class_folder = os.path.join(test_images_dir, class_name)\n",
    "    if os.path.isdir(class_folder):  # Only include folders\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
    "                image_paths.append(os.path.join(class_folder, filename))\n",
    "\n",
    "# Loop through each image, load, predict, and display the result\n",
    "for img_path in image_paths:\n",
    "    # Load image and resize to match model input\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "    # Convert the image to an array and normalize\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize image\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # Get the class names from your generator\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "    # Display the image and the prediction\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.title(f\"Predicted Event: {predicted_class}\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image: {img_path} | Predicted Event: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647b294-f9f8-49b7-be5e-92ce67ccdcc3",
   "metadata": {
    "id": "c647b294-f9f8-49b7-be5e-92ce67ccdcc3"
   },
   "outputs": [],
   "source": [
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0  # Ensure normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784d70b-6a26-4837-8800-5d4467744971",
   "metadata": {
    "id": "a784d70b-6a26-4837-8800-5d4467744971",
    "outputId": "dea49daa-fa54-4d63-fab2-405b1aea21cf"
   },
   "outputs": [],
   "source": [
    "class_names = list(train_generator.class_indices.keys())  # Get class labels\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "print(f\"Predicted Event: {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a35fcf-57b4-42d4-98c9-d78a34b18103",
   "metadata": {
    "id": "f4a35fcf-57b4-42d4-98c9-d78a34b18103",
    "outputId": "7a73d1cf-f164-47dd-a57e-307864328b9b"
   },
   "outputs": [],
   "source": [
    "img_path = 'downloads/test/fainting/fait1.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "print(f\"Predicted Event: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a025d-0533-4461-b9d7-6bdd25378eea",
   "metadata": {
    "id": "0d6a025d-0533-4461-b9d7-6bdd25378eea",
    "outputId": "4d14f462-85c1-4357-9046-0f38ebdd56cd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the true labels and predicted labels\n",
    "y_true = test_generator.classes  # Actual labels\n",
    "y_pred = model.predict(test_generator)  # Predicted labels\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert predictions to class indices\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_generator.class_indices.keys(), yticklabels=train_generator.class_indices.keys())\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18932e-fecb-49e8-970c-b966be015497",
   "metadata": {
    "id": "1c18932e-fecb-49e8-970c-b966be015497",
    "outputId": "bdfb4cce-459b-4d52-99bb-31aaa4def688"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ensure files exist before prediction\n",
    "def safe_predict(generator):\n",
    "    for batch_images, batch_labels in generator:\n",
    "        valid_images = []\n",
    "\n",
    "        # Check if each image in the batch exists\n",
    "        for image in batch_images:\n",
    "            image_path = image  # Assuming image path can be extracted from the image (you may need to adjust this)\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Skipping missing file: {image_path}\")\n",
    "                continue  # Skip this image if missing\n",
    "\n",
    "            valid_images.append(image)  # Add valid image to the list\n",
    "\n",
    "        # Yield only valid images in the batch\n",
    "        yield np.array(valid_images), batch_labels\n",
    "\n",
    "# Use safe_predict to generate predictions\n",
    "y_pred = model.predict(safe_predict(test_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf8d1c-4219-4434-9ed4-086c8a0a27b1",
   "metadata": {
    "id": "e3bf8d1c-4219-4434-9ed4-086c8a0a27b1",
    "outputId": "9032dcdc-118e-4244-8249-03751ce50870"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data augmentation setup\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values\n",
    "    rotation_range=30,  # Random rotation up to 30 degrees\n",
    "    width_shift_range=0.2,  # Horizontal shift\n",
    "    height_shift_range=0.2,  # Vertical shift\n",
    "    shear_range=0.2,  # Shearing transformation\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    horizontal_flip=True,  # Flip images horizontally\n",
    "    fill_mode='nearest'  # Fill missing pixels\n",
    ")\n",
    "\n",
    "# Test data should NOT have augmentation, only normalization\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load augmented training data from directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'downloads/train',  # Replace with your training dataset path\n",
    "    target_size=(150, 150),  # Resize images to this size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Use 'binary' for two classes\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'downloads/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91762e6-baf1-4322-8a43-42d460cfe540",
   "metadata": {
    "id": "d91762e6-baf1-4322-8a43-42d460cfe540",
    "outputId": "c5e2b520-e0f9-48d1-9e46-3c4ae56f978c"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with augmented data\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(test_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419857c-1b3c-436e-abf4-994bdad76a8f",
   "metadata": {
    "id": "f419857c-1b3c-436e-abf4-994bdad76a8f",
    "outputId": "459afc59-1276-4907-b183-321bcf5d2ecd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "augmented_images, _ = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(augmented_images[i])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f7816-3189-4207-80fa-139366ac91cf",
   "metadata": {
    "id": "242f7816-3189-4207-80fa-139366ac91cf",
    "outputId": "e518d540-6348-4dd8-f610-d858da5ada80"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the model in the recommended format\n",
    "model.save('augmented_model.keras')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
